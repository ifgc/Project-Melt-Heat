{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072dbe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the Random Forest model from the joblib file\n",
    "model_path = 'RFRexp5-3-Monster/RUN7/random_forest_regressor.joblib'\n",
    "rfr = joblib.load(model_path)\n",
    "\n",
    "# Load your dataset (replace 'path_to_your_data.csv' with your actual dataset path)\n",
    "data_path = 'TrainingSetundLOGG.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "features = data.drop(columns=['APOGEE_LOGG'])\n",
    "target = data['APOGEE_LOGG']\n",
    "\n",
    "# Create the preprocessing pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Imputes missing values with mean\n",
    "    ('scaling', StandardScaler()),  #Standardizes the features\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k=65)),  # Step 3: Select top 65 (all) features\n",
    "])\n",
    "\n",
    "# Fit and transform the data using the pipeline\n",
    "X_preprocessed = pipeline.fit_transform(features, target)\n",
    "\n",
    "for n in np.arange(0.01, 0.99, 0.01):\n",
    "    # Split data into training and test sets\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, target, test_size=n, random_state=4180) #been messing with diff rand states\n",
    "\n",
    "    # Make predictions using the loaded model\n",
    "    predictions = rfr.predict(X_test)\n",
    "\n",
    "    # Print the predictions\n",
    "    #print(predictions)\n",
    "\n",
    "    # Optionally, if you want to evaluate the model, you can compare predictions with the actual target\n",
    "    # Calculate Mean Squared Error (MSE) and R^2 Score\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r_squared = r2_score(y_test, predictions)\n",
    "    \n",
    "    print(n)\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'R^2 Score: {r_squared}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27fbd3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Actual  Predicted  Difference  Absolute Error  Percentage Error\n",
      "33752 -0.369348  -0.049698   -0.319650        0.319650         86.544379\n",
      "54419 -0.367129  -0.095812   -0.271317        0.271317         73.902436\n",
      "53942 -0.367129  -0.114420   -0.252708        0.252708         68.833698\n",
      "57946 -0.333298  -0.106344   -0.226954        0.226954         68.093420\n",
      "57716 -0.333298  -0.191212   -0.142086        0.142086         42.630368\n",
      "...         ...        ...         ...             ...               ...\n",
      "37528  5.175170   4.773844    0.401326        0.401326          7.754845\n",
      "12870  5.186769   4.745330    0.441440        0.441440          8.510885\n",
      "14506  5.186795   4.791249    0.395546        0.395546          7.626013\n",
      "36944  5.254289   4.930914    0.323374        0.323374          6.154486\n",
      "147    5.258421   4.783472    0.474949        0.474949          9.032166\n",
      "\n",
      "[47342 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the predictions vs actual values\n",
    "results_df = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
    "results_df = results_df.sort_values(by=['Actual'])\n",
    "results_df['Difference'] = results_df['Actual'] - results_df['Predicted']\n",
    "\n",
    "\n",
    "results_df['Absolute Error'] = np.abs(results_df['Difference'])\n",
    "results_df['Percentage Error'] = (results_df['Difference'] / results_df['Actual']) * 100\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df332a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot predicted vs actual with a line of slope 1\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m'\u001b[39m], results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m'\u001b[39m], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot([results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin(), results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()],\n\u001b[1;32m      5\u001b[0m          [results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin(), results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()],\n\u001b[1;32m      6\u001b[0m          color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Line with slope of 1\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot predicted vs actual with a line of slope 1\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.scatter(results_df['Actual'], results_df['Predicted'], color='blue', alpha=0.6)\n",
    "plt.plot([results_df['Actual'].min(), results_df['Actual'].max()],\n",
    "         [results_df['Actual'].min(), results_df['Actual'].max()],\n",
    "         color='red', linestyle='--', linewidth=2)  # Line with slope of 1\n",
    "plt.xlabel('Actual Values', fontsize=14)\n",
    "plt.ylabel('Predicted Values', fontsize=14)\n",
    "plt.title('Scatter plot of Predicted vs. Actual Values', fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b169366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot actual vs. actual - predicted\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.scatter(results_df['Actual'], results_df['Difference'], color='blue', alpha=0.6)\n",
    "plt.axhline(0, color='red', linestyle='--')  # Add a horizontal line at y=0 for reference\n",
    "plt.xlabel('Actual Values', fontsize=14)\n",
    "plt.ylabel('A-P', fontsize=14)\n",
    "plt.title('Scatter plot of Difference vs. Actual Values', fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot actual vs. actual - predicted\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.scatter(results_df['Predicted'], results_df['Difference'], color='blue', alpha=0.6)\n",
    "plt.axhline(0, color='red', linestyle='--')  # Add a horizontal line at y=0 for reference\n",
    "plt.xlabel('Predicted Values', fontsize=14)\n",
    "plt.ylabel('A-P', fontsize=14)\n",
    "plt.title('Scatter plot of Difference vs. Predicted Values', fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fa7680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Residual plot\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.scatter(results_df['Actual'], results_df['Difference'], color='blue', alpha=0.6)\n",
    "plt.axhline(0, color='red', linestyle='--')  # Add a horizontal line at y=0 for reference\n",
    "plt.xlabel('Actual Values', fontsize=14)\n",
    "plt.ylabel('Actual - Predicted', fontsize=14)\n",
    "plt.title('Residual Plot (Actual - Predicted vs. Actual)', fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1678fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Absolute Error plot\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.scatter(results_df['Actual'], results_df['Absolute Error'], color='blue', alpha=0.6)\n",
    "plt.xlabel('Actual Values', fontsize=14)\n",
    "plt.ylabel('Absolute Error', fontsize=14)\n",
    "plt.title('Absolute Error vs. Actual Values', fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfa2dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Percentage Error plot on a log10 scale\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.scatter(results_df['Actual'], np.abs(results_df['Percentage Error']), color='blue', alpha=0.6)\n",
    "plt.yscale('log')\n",
    "plt.axhline(1, color='red', linestyle='--')  # Add a horizontal line at y=1 for reference\n",
    "plt.xlabel('Actual Values', fontsize=14)\n",
    "plt.ylabel('Percentage Error (log scale)', fontsize=14)\n",
    "plt.title('Percentage Error vs. Actual Values (log scale)', fontsize=18)\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca74068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 4: Histogram of Errors\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.hist(results_df['Absolute Error'], bins=10, color='blue', alpha=0.6)\n",
    "plt.xlabel('Error (Actual - Predicted)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.yscale('log')\n",
    "plt.title('Histogram of Errors', fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750fbe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "plt.figure(figsize=(14, 10))\n",
    "stats.probplot(results_df['Difference'], dist=\"norm\", plot=plt)\n",
    "plt.title('QQ Plot of Errors', fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6072176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of the residuals\n",
    "std_dev = np.std(results_df['Difference'])\n",
    "\n",
    "# Plot residuals with standard deviation lines\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.scatter(results_df['Actual'], results_df['Difference'], color='blue', alpha=0.6, label='Residuals')\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=1, label='Mean Error (0)')\n",
    "plt.axhline(std_dev, color='green', linestyle='--', linewidth=1, label=f'+1 Std Dev ({std_dev:.2f})')\n",
    "plt.axhline(-std_dev, color='green', linestyle='--', linewidth=1, label=f'-1 Std Dev ({std_dev:.2f})')\n",
    "plt.xlabel('Actual Values', fontsize=14)\n",
    "plt.ylabel('Actual - Predicted', fontsize=14)\n",
    "plt.title('Residual Plot with Standard Deviation Lines', fontsize=18)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Define the updated list of colors\n",
    "colors = [\n",
    "    '#5d0c9d', '#6612ab', '#6f19b9', '#1500db', '#1500db', '#1d13dd',\n",
    "    '#2626df', '#2e38e2', '#374be4', '#3f5ee6', '#4771e8', '#5084ea',\n",
    "    '#5896ed', '#61a9ef', '#69bcf1', '#78c5ee', '#39a857', '#40b65e',\n",
    "    '#4fd370', '#2ae852', '#27f143', '#13f822', '#6dff00', '#92ff00',\n",
    "    '#b6ff00', '#dbff00', '#ffff00', '#fff200', '#ffe500', '#ffd800',\n",
    "    '#ffcc00', '#ffbf00', '#ffb200', '#ffa500', '#ff0000', '#ff1919'\n",
    "]\n",
    "\n",
    "# Create a colormap object with the updated colors list\n",
    "cmap = LinearSegmentedColormap.from_list(\"custom_gradient_with_brightened_color\", colors, N=len(colors))\n",
    "len(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c440a841",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a ListedColormap object\n",
    "cmap = mcolors.ListedColormap(colors, name='my_rainbow')\n",
    "\n",
    "cmap.set_under('white', alpha=0)  # Make values of zero transparent\n",
    "cmap_args = dict(cmap=cmap, vmin=1, vmax=600)\n",
    "plt.figure(figsize=(14, 10))\n",
    "#plt.scatter(results_df['Actual'], results_df['Predicted'], color='blue', alpha=0.6)\n",
    "plt.hexbin(results_df['Actual'], results_df['Predicted'], gridsize=80, **cmap_args)  # Using cmap_args for colormap setup\n",
    "plt.plot([results_df['Actual'].min(), results_df['Actual'].max()],\n",
    "       [results_df['Actual'].min(), results_df['Actual'].max()],\n",
    "        color='red', linestyle='--', linewidth=0.5)  # Line with slope of 1\n",
    "plt.xlabel('Actual Values', fontsize=14)\n",
    "plt.ylabel('Predicted Values', fontsize=14)\n",
    "plt.title('Heatmap of Predicted vs. Actual Values', fontsize=18)\n",
    "plt.colorbar(label='Count')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da40a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of actual values for which you want to calculate sigma significance\n",
    "min_actual_value = 4  # Replace with your minimum actual value\n",
    "max_actual_value = results_df['Actual'].max()  # Replace with your maximum actual value\n",
    "\n",
    "# Filter the results to include only the desired range of actual values\n",
    "filteredResultsDF = results_df[(results_df['Actual'] >= min_actual_value) & (results_df['Actual'] <= max_actual_value)]\n",
    "\n",
    "# Calculate the mean and standard deviation of the differences (residuals)\n",
    "mean_difference = filteredResultsDF['Difference'].mean()\n",
    "std_difference = filteredResultsDF['Difference'].std()\n",
    "\n",
    "# Calculate sigma significance\n",
    "sigma_significance = mean_difference / std_difference\n",
    "\n",
    "print(f'Mean Difference: {mean_difference}')\n",
    "print(f'Standard Deviation of Difference: {std_difference}')\n",
    "print(f'Sigma Significance: {sigma_significance}')\n",
    "\n",
    "mse = mean_squared_error(filteredResultsDF['Actual'], filteredResultsDF['Predicted'])\n",
    "r_squared = r2_score(filteredResultsDF['Actual'], filteredResultsDF['Predicted'])\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r_squared}')\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.hist(filteredResultsDF['Absolute Error'], bins=10, color='blue', alpha=0.6)\n",
    "plt.xlabel('Error (Actual - Predicted)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.yscale('log')\n",
    "plt.title('Histogram of Errors', fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0bdeed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the range of actual values for which you want to calculate sigma significance\n",
    "min_actual_value = results_df['Actual'].min()\n",
    "max_actual_value = 4 \n",
    "\n",
    "# Filter the results to include only the desired range of actual values\n",
    "filteredResultsDF = results_df[(results_df['Actual'] >= min_actual_value) & (results_df['Actual'] <= max_actual_value)]\n",
    "\n",
    "# Calculate the mean and standard deviation of the differences (residuals)\n",
    "mean_difference = filteredResultsDF['Difference'].mean()\n",
    "std_difference = filteredResultsDF['Difference'].std()\n",
    "\n",
    "# Calculate sigma significance\n",
    "sigma_significance = mean_difference / std_difference\n",
    "\n",
    "print(f'Mean Difference: {mean_difference}')\n",
    "print(f'Standard Deviation of Difference: {std_difference}')\n",
    "print(f'Sigma Significance: {sigma_significance}')\n",
    "\n",
    "mse = mean_squared_error(filteredResultsDF['Actual'], filteredResultsDF['Predicted'])\n",
    "r_squared = r2_score(filteredResultsDF['Actual'], filteredResultsDF['Predicted'])\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r_squared}')\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.hist(filteredResultsDF['Absolute Error'], bins=10, color='blue', alpha=0.6)\n",
    "plt.xlabel('Error (Actual - Predicted)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.yscale('log')\n",
    "plt.title('Histogram of Errors', fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of actual values for which you want to calculate sigma significance\n",
    "min_actual_value =results_df['Actual'].min() # Replace with your minimum actual value\n",
    "max_actual_value = results_df['Actual'].max() # Replace with your maximum actual value\n",
    "\n",
    "# Filter the results to include only the desired range of actual values\n",
    "filteredResultsDF = results_df[(results_df['Actual'] >= min_actual_value) & (results_df['Actual'] <= max_actual_value)]\n",
    "\n",
    "# Calculate the mean and standard deviation of the differences (residuals)\n",
    "mean_difference = filteredResultsDF['Difference'].mean()\n",
    "std_difference = filteredResultsDF['Difference'].std()\n",
    "\n",
    "# Calculate sigma significance\n",
    "sigma_significance = mean_difference / std_difference\n",
    "\n",
    "print(f'Mean Difference: {mean_difference}')\n",
    "print(f'Standard Deviation of Difference: {std_difference}')\n",
    "print(f'Sigma Significance: {sigma_significance}')\n",
    "\n",
    "mse = mean_squared_error(filteredResultsDF['Actual'], filteredResultsDF['Predicted'])\n",
    "r_squared = r2_score(filteredResultsDF['Actual'], filteredResultsDF['Predicted'])\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r_squared}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e1a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of the residuals\n",
    "std_dev = np.std(filteredResultsDF['Difference'])\n",
    "\n",
    "# Plot residuals with standard deviation lines\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.scatter(filteredResultsDF['Actual'], filteredResultsDF['Difference'], color='blue', alpha=0.6, label='Residuals')\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=1, label='Mean Error (0)')\n",
    "plt.axhline(std_dev, color='green', linestyle='--', linewidth=1, label=f'+1 Std Dev ({std_dev:.2f})')\n",
    "plt.axhline(-std_dev, color='green', linestyle='--', linewidth=1, label=f'-1 Std Dev ({std_dev:.2f})')\n",
    "plt.xlabel('Actual Values', fontsize=14)\n",
    "plt.ylabel('Actual - Predicted', fontsize=14)\n",
    "plt.title('Residual Plot with Standard Deviation Lines', fontsize=18)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project_meltheat_v2)",
   "language": "python",
   "name": "project_meltheat_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
